# ğŸ•µï¸ Java Spark Data Analyzer

<div align="center">

![Java](https://img.shields.io/badge/Java-11+-orange.svg)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.4.1-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

**Um aplicativo Java de anÃ¡lise de dados com Apache Spark que compete diretamente com soluÃ§Ãµes em Python.**

</div>

---

## âœ¨ Principais Funcionalidades

- ğŸ“Š **Carregamento intuitivo de dados** - Suporte para CSV com diversas opÃ§Ãµes de configuraÃ§Ã£o
- ğŸ” **VisualizaÃ§Ã£o interativa** - ExibiÃ§Ã£o de schemas, amostras e estatÃ­sticas descritivas
- ğŸ”„ **TransformaÃ§Ãµes poderosas** - SeleÃ§Ã£o de colunas, criaÃ§Ã£o de novas colunas, renomeaÃ§Ã£o e ordenaÃ§Ã£o
- ğŸ” **Filtros avanÃ§ados** - AplicaÃ§Ã£o de condiÃ§Ãµes para filtrar dados com precisÃ£o
- ğŸ“ˆ **AgregaÃ§Ãµes flexÃ­veis** - FunÃ§Ãµes como mÃ©dia, soma, mÃ­nimo, mÃ¡ximo e contagem
- âš™ï¸ **Tratamento de dados** - RemoÃ§Ã£o eficiente de duplicatas e valores nulos
- ğŸ’¾ **MÃºltiplos formatos de exportaÃ§Ã£o** - Salvamento em CSV, Parquet e JSON

## ğŸ“‹ Requisitos

- Java 8 ou 11 (recomendado)
- Java 17+ (requer configuraÃ§Ãµes adicionais)
- Apache Maven
- MemÃ³ria suficiente para processar seus conjuntos de dados

## âš™ï¸ ConfiguraÃ§Ãµes por VersÃ£o do Java

### Java 8 ou 11 (Recomendado)
Java 8 ou 11 funcionam diretamente sem configuraÃ§Ãµes adicionais.

### Java 17+
Para usar com Java 17 ou superior, Ã© necessÃ¡rio adicionar as seguintes opÃ§Ãµes JVM:
```bash
--add-opens=java.base/java.nio=ALL-UNNAMED
--add-opens=java.base/sun.nio.ch=ALL-UNNAMED
--add-opens=java.base/java.util=ALL-UNNAMED
--add-opens=java.base/java.lang.invoke=ALL-UNNAMED
--add-opens=java.base/java.util.concurrent=ALL-UNNAMED
```

## ğŸ”§ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/bulletdev/java-spark-data-analyzer.git
cd java-spark-data-analyzer
```

2. Compile o projeto:
```bash
mvn clean package
```

## â–¶ï¸ ExecuÃ§Ã£o

### Usando Maven

```bash
# Para Java 8/11
mvn exec:java -Dexec.mainClass="com.dataanalyzer.DataAnalyzer"

# Para Java 17+
mvn exec:java -Dexec.mainClass="com.dataanalyzer.DataAnalyzer" -Dexec.args="" \
-Dexec.cleanupDaemonThreads=false \
-Dexec.jvmArgs="--add-opens=java.base/java.nio=ALL-UNNAMED \
--add-opens=java.base/sun.nio.ch=ALL-UNNAMED \
--add-opens=java.base/java.util=ALL-UNNAMED \
--add-opens=java.base/java.lang.invoke=ALL-UNNAMED \
--add-opens=java.base/java.util.concurrent=ALL-UNNAMED"
```

### Usando o JAR compilado

```bash
# Para Java 8/11
java -jar target/java-spark-data-analyzer-1.0-SNAPSHOT-jar-with-dependencies.jar

# Para Java 17+
java --add-opens=java.base/java.nio=ALL-UNNAMED \
--add-opens=java.base/sun.nio.ch=ALL-UNNAMED \
--add-opens=java.base/java.util=ALL-UNNAMED \
--add-opens=java.base/java.lang.invoke=ALL-UNNAMED \
--add-opens=java.base/java.util.concurrent=ALL-UNNAMED \
-jar target/java-spark-data-analyzer-1.0-SNAPSHOT-jar-with-dependencies.jar
```

## ğŸ“ Estrutura do Projeto

```
java-spark-data-analyzer/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â”œâ”€â”€ java/
â”‚       â”‚   â””â”€â”€ com/
â”‚       â”‚       â””â”€â”€ dataanalyzer/
â”‚       â”‚           â””â”€â”€ DataAnalyzer.java
â”‚       â””â”€â”€ resources/
â”‚           â””â”€â”€ dados_vendas.csv
â”œâ”€â”€ pom.xml
â””â”€â”€ README.md
```

## â“ SoluÃ§Ã£o de Problemas

### Windows e Hadoop

O Spark usa algumas funcionalidades do Hadoop que podem gerar avisos no Windows. Se encontrar avisos relacionados ao `winutils.exe` ou `HADOOP_HOME`, vocÃª pode:

1. IgnorÃ¡-los (nÃ£o afetam a funcionalidade bÃ¡sica do aplicativo)
2. Configurar o ambiente Hadoop para Windows:
    - Baixe o [winutils.exe](https://github.com/cdarlint/winutils)
    - Crie uma pasta `C:\hadoop\bin` e coloque o arquivo lÃ¡
    - Configure a variÃ¡vel de ambiente `HADOOP_HOME=C:\hadoop`
    - Adicione `%HADOOP_HOME%\bin` ao PATH

### Aviso de "illegal reflective access"

Este aviso pode aparecer ao usar Java 11. Ã‰ normal e nÃ£o afeta o funcionamento do aplicativo.

## ğŸ“Š Dados de Exemplo

O projeto inclui um arquivo de exemplo `dados_vendas.csv` com dados fictÃ­cios de vendas de produtos eletrÃ´nicos para testar as funcionalidades do aplicativo. Este arquivo contÃ©m os seguintes campos:

| Campo | DescriÃ§Ã£o |
|-------|-----------|
| ID | Identificador Ãºnico da venda |
| Data | Data da venda (formato YYYY-MM-DD) |
| Produto | Nome do produto vendido |
| Categoria | Categoria do produto |
| Preco | PreÃ§o unitÃ¡rio do produto |
| Quantidade | Quantidade vendida |
| ClienteID | Identificador do cliente |
| Regiao | RegiÃ£o geogrÃ¡fica da venda |
| Vendedor | Nome do vendedor |
| Desconto | Percentual de desconto aplicado (decimal) |

## ğŸ“ Uso BÃ¡sico

Ao iniciar o aplicativo, vocÃª verÃ¡ um menu interativo:

1. **Carregue os dados** usando a opÃ§Ã£o 1
    - Digite o caminho para o CSV ou use "example" para o arquivo de exemplo
    - Confirme se o arquivo tem cabeÃ§alho (s/n)
    - Especifique o delimitador (geralmente vÃ­rgula)

2. **Explore os dados**:
    - OpÃ§Ã£o 2: Ver a estrutura (schema) dos dados
    - OpÃ§Ã£o 3: Ver uma amostra dos dados
    - OpÃ§Ã£o 4: Ver estatÃ­sticas descritivas

3. **Analise e transforme os dados**:
    - OpÃ§Ã£o 5: Filtrar registros
    - OpÃ§Ã£o 6: Agregar dados (ex: soma de vendas por regiÃ£o)
    - OpÃ§Ã£o 7: Transformar dados (criar colunas, renomear, etc.)

4. **Salve os resultados** usando a opÃ§Ã£o 8

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Se vocÃª encontrar bugs ou tiver sugestÃµes de melhorias, abra uma issue ou envie um pull request.

## ğŸ“œ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo LICENSE para detalhes.

---

<div align="center">
  <p><strong>Por que Java para anÃ¡lise de dados?</strong> Desempenho superior, tipagem estÃ¡tica, multithreading robusto e integraÃ§Ã£o perfeita com sistemas empresariais.</p>
  <p><em>Java Spark Data Analyzer - A resposta Java para a anÃ¡lise de dados em Python.</em></p>
</div>