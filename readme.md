# üïµÔ∏è Java Spark Data Analyzer

<div align="center">

![Java](https://img.shields.io/badge/Java-11+-orange.svg)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.4.1-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

**Um aplicativo Java de an√°lise de dados com Apache Spark que compete diretamente com solu√ß√µes em Python.**

</div>

---

## ‚ú® Principais Funcionalidades

- üìä **Carregamento intuitivo de dados** - Suporte para CSV com diversas op√ß√µes de configura√ß√£o
- üîç **Visualiza√ß√£o interativa** - Exibi√ß√£o de schemas, amostras e estat√≠sticas descritivas
- üîÑ **Transforma√ß√µes poderosas** - Sele√ß√£o de colunas, cria√ß√£o de novas colunas, renomea√ß√£o e ordena√ß√£o
- üîé **Filtros avan√ßados** - Aplica√ß√£o de condi√ß√µes para filtrar dados com precis√£o
- üìà **Agrega√ß√µes flex√≠veis** - Fun√ß√µes como m√©dia, soma, m√≠nimo, m√°ximo e contagem
- ‚öôÔ∏è **Tratamento de dados** - Remo√ß√£o eficiente de duplicatas e valores nulos
- üíæ **M√∫ltiplos formatos de exporta√ß√£o** - Salvamento em CSV, Parquet e JSON

## üìã Requisitos

- Java 8 ou 11 (recomendado)
- Java 17+ (requer configura√ß√µes adicionais)
- Apache Maven
- Mem√≥ria suficiente para processar seus conjuntos de dados

## ‚öôÔ∏è Configura√ß√µes por Vers√£o do Java

### Java 8 ou 11 (Recomendado)
Java 8 ou 11 funcionam diretamente sem configura√ß√µes adicionais.

### Java 17+
Para usar com Java 17 ou superior, √© necess√°rio adicionar as seguintes op√ß√µes JVM:
```bash
--add-opens=java.base/java.nio=ALL-UNNAMED
--add-opens=java.base/sun.nio.ch=ALL-UNNAMED
--add-opens=java.base/java.util=ALL-UNNAMED
--add-opens=java.base/java.lang.invoke=ALL-UNNAMED
--add-opens=java.base/java.util.concurrent=ALL-UNNAMED
```

## üîß Instala√ß√£o

1. Clone o reposit√≥rio:
```bash
git clone https://github.com/bulletdev/java-spark-data-analyzer.git
cd java-spark-data-analyzer
```

2. Compile o projeto:
```bash
mvn clean package
```

## ‚ñ∂Ô∏è Execu√ß√£o

### Usando Maven

```bash
# Para Java 8/11
mvn exec:java -Dexec.mainClass="com.dataanalyzer.DataAnalyzer"

# Para Java 17+
mvn exec:java -Dexec.mainClass="com.dataanalyzer.DataAnalyzer" -Dexec.args="" \
-Dexec.cleanupDaemonThreads=false \
-Dexec.jvmArgs="--add-opens=java.base/java.nio=ALL-UNNAMED \
--add-opens=java.base/sun.nio.ch=ALL-UNNAMED \
--add-opens=java.base/java.util=ALL-UNNAMED \
--add-opens=java.base/java.lang.invoke=ALL-UNNAMED \
--add-opens=java.base/java.util.concurrent=ALL-UNNAMED"
```

### Usando o JAR compilado

```bash
# Para Java 8/11
java -jar target/java-spark-data-analyzer-1.0-SNAPSHOT-jar-with-dependencies.jar

# Para Java 17+
java --add-opens=java.base/java.nio=ALL-UNNAMED \
--add-opens=java.base/sun.nio.ch=ALL-UNNAMED \
--add-opens=java.base/java.util=ALL-UNNAMED \
--add-opens=java.base/java.lang.invoke=ALL-UNNAMED \
--add-opens=java.base/java.util.concurrent=ALL-UNNAMED \
-jar target/java-spark-data-analyzer-1.0-SNAPSHOT-jar-with-dependencies.jar
```

## ‚ùì Solu√ß√£o de Problemas

### Windows e Hadoop

O Spark usa algumas funcionalidades do Hadoop que podem gerar avisos no Windows. Se encontrar avisos relacionados ao `winutils.exe` ou `HADOOP_HOME`, voc√™ pode:

1. Ignor√°-los (n√£o afetam a funcionalidade b√°sica do aplicativo)
2. Configurar o ambiente Hadoop para Windows:
    - Baixe o [winutils.exe](https://github.com/cdarlint/winutils)
    - Crie uma pasta `C:\hadoop\bin` e coloque o arquivo l√°
    - Configure a vari√°vel de ambiente `HADOOP_HOME=C:\hadoop`
    - Adicione `%HADOOP_HOME%\bin` ao PATH

### Aviso de "illegal reflective access"

Este aviso pode aparecer ao usar Java 11. √â normal e n√£o afeta o funcionamento do aplicativo.

## üìä Dados de Exemplo

O projeto inclui um arquivo de exemplo `dados_vendas.csv` com dados fict√≠cios de vendas de produtos eletr√¥nicos para testar as funcionalidades do aplicativo. Este arquivo cont√©m os seguintes campos:

| Campo | Descri√ß√£o |
|-------|-----------|
| ID | Identificador √∫nico da venda |
| Data | Data da venda (formato YYYY-MM-DD) |
| Produto | Nome do produto vendido |
| Categoria | Categoria do produto |
| Preco | Pre√ßo unit√°rio do produto |
| Quantidade | Quantidade vendida |
| ClienteID | Identificador do cliente |
| Regiao | Regi√£o geogr√°fica da venda |
| Vendedor | Nome do vendedor |
| Desconto | Percentual de desconto aplicado (decimal) |

## üìù Uso B√°sico

Ao iniciar o aplicativo, voc√™ ver√° um menu interativo:

1. **Carregue os dados** usando a op√ß√£o 1
    - Digite o caminho para o CSV ou use "example" para o arquivo de exemplo
    - Confirme se o arquivo tem cabe√ßalho (s/n)
    - Especifique o delimitador (geralmente v√≠rgula)

2. **Explore os dados**:
    - Op√ß√£o 2: Ver a estrutura (schema) dos dados
    - Op√ß√£o 3: Ver uma amostra dos dados
    - Op√ß√£o 4: Ver estat√≠sticas descritivas

3. **Analise e transforme os dados**:
    - Op√ß√£o 5: Filtrar registros
    - Op√ß√£o 6: Agregar dados (ex: soma de vendas por regi√£o)
    - Op√ß√£o 7: Transformar dados (criar colunas, renomear, etc.)

4. **Salve os resultados** usando a op√ß√£o 8

## ü§ù Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! Se voc√™ encontrar bugs ou tiver sugest√µes de melhorias, abra uma issue ou envie um pull request.

## üìú Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo LICENSE para detalhes.

---

<div align="center">
  <p><strong>Por que Java para an√°lise de dados?</strong> Desempenho superior, tipagem est√°tica, multithreading robusto e integra√ß√£o perfeita com sistemas empresariais.</p>
  <p><em>Java Spark Data Analyzer - A resposta Java para a an√°lise de dados em Python.</em></p>
</div>